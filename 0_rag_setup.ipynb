{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "baa42f3a",
   "metadata": {},
   "source": [
    "This notebook introduces Retrieval Augmented Generation (RAG) and demonstrates how to set up, ingest data into, and retrieve information from a vector database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9180f528",
   "metadata": {},
   "source": [
    "# Background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ac5dbc",
   "metadata": {},
   "source": [
    "## How will LLM know your data?\n",
    "\n",
    "LLMs are pretrained on vast amounts of internet data. It never has seen your data thus if you ask it a question related "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7c618e",
   "metadata": {},
   "source": [
    "<img src=\"assets/How would it know your data.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221e9d21",
   "metadata": {},
   "source": [
    "## Manually pass document with query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6ea0dd",
   "metadata": {},
   "source": [
    "<image src = \"assets/Query with document.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3ed320",
   "metadata": {},
   "source": [
    "## Retrieval Augmented Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e1f9bc",
   "metadata": {},
   "source": [
    "<image src = \"assets/Retrieval Augmented Generation.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b493780",
   "metadata": {},
   "source": [
    "# Code implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b92633",
   "metadata": {},
   "source": [
    "## Ingest into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf35eab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0220e4c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(\"configs.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd1e63ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder with .html files\n",
    "SOURCE_DIR = \"data_files\"\n",
    "# Persistent vector database directory\n",
    "DB_DIR = \"vector_db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2d829ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      " 50%|█████     | 1/2 [00:01<00:01,  1.50s/it]libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.03it/s]\n"
     ]
    }
   ],
   "source": [
    "loader = DirectoryLoader(SOURCE_DIR, glob=\"**/*.txt\", show_progress=True)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdfeca37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 files loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(docs)} files loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bcf5d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split each book into smaller chunks\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=400)\n",
    "chunks = splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5edca90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1381 chunks created successfully.\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(chunks)} chunks created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "695b0098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Ingestion complete. Persistent DB stored at: vector_db\n"
     ]
    }
   ],
   "source": [
    "# create folder if it doesnt exist\n",
    "os.makedirs(DB_DIR, exist_ok=True)\n",
    "\n",
    "# vectorize document chunks using text embedding model\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\"),\n",
    "    persist_directory=DB_DIR,\n",
    ")\n",
    "print(f\"✅ Ingestion complete. Persistent DB stored at: {DB_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2763c72a",
   "metadata": {},
   "source": [
    "## Fetch from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7d75721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load persistent vector DB ===\n",
    "vectordb = Chroma(\n",
    "    persist_directory=DB_DIR,\n",
    "    embedding_function=OpenAIEmbeddings(model=\"text-embedding-3-small\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adf3457d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieval using chromaDB\n",
    "query = \"Who is Irene Adler?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9354277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch top 3 most similar chunks\n",
    "results = vectordb.similarity_search(query, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47b485f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------Result 1-------------------:\n",
      "Source: data_files/The Adventures of Sherlock Holmes.txt\n",
      "Truncated Content: I. A SCANDAL IN BOHEMIA\n",
      "\n",
      "I.\n",
      "\n",
      "To Sherlock Holmes she is always _the_ woman. I have seldom heard him m...\n",
      "\n",
      "-------------------Result 2-------------------:\n",
      "Source: data_files/The Adventures of Sherlock Holmes.txt\n",
      "Truncated Content: “I then lounged down the street and found, as I expected, that there was a mews in a lane which runs...\n",
      "\n",
      "-------------------Result 3-------------------:\n",
      "Source: data_files/The Adventures of Sherlock Holmes.txt\n",
      "Truncated Content: It was close upon four before the door opened, and a drunken-looking groom, ill-kempt and side-whisk...\n"
     ]
    }
   ],
   "source": [
    "for i, doc in enumerate(results, 1):\n",
    "    print(f\"\\n-------------------Result {i}-------------------:\")\n",
    "    print(f\"Source: {doc.metadata.get('source', 'unknown')}\")\n",
    "    print(f\"Truncated Content: {doc.page_content[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc6f46b",
   "metadata": {},
   "source": [
    "## Generate LLM response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "792d5196",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Who is Irene Adler?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fe350c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the LLM and RetrievalQA chain\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    return_source_documents=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8760582a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = qa_chain.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f863d495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------Source: data_files/The Adventures of Sherlock Holmes.txt-------------------:\n",
      "Truncated Content: I. A SCANDAL IN BOHEMIA\n",
      "\n",
      "I.\n",
      "\n",
      "To Sherlock Holmes she is always _the_ woman. I have seldom heard him m...\n",
      "\n",
      "-------------------Source: data_files/The Adventures of Sherlock Holmes.txt-------------------:\n",
      "Truncated Content: “I then lounged down the street and found, as I expected, that there was a mews in a lane which runs...\n",
      "\n",
      "-------------------Source: data_files/The Adventures of Sherlock Holmes.txt-------------------:\n",
      "Truncated Content: It was close upon four before the door opened, and a drunken-looking groom, ill-kempt and side-whisk...\n",
      "\n",
      "-------------------Source: data_files/The Adventures of Sherlock Holmes.txt-------------------:\n",
      "Truncated Content: “Mr. Sherlock Holmes, I believe?” said she.\n",
      "\n",
      "“I am Mr. Holmes,” answered my companion, looking at he...\n"
     ]
    }
   ],
   "source": [
    "# print source and first 500 characters of page content\n",
    "for doc in response[\"source_documents\"]:\n",
    "    print(\n",
    "        f\"\\n-------------------Source: {doc.metadata.get('source', 'unknown')}-------------------:\"\n",
    "    )\n",
    "    # preview first 100 chars\n",
    "    print(f\"Truncated Content: {doc.page_content[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b62c587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# User Query:\n",
      " Who is Irene Adler?\n",
      "\n",
      "# LLM Response:\n",
      " Irene Adler is a character in Arthur Conan Doyle's story \"A Scandal in Bohemia.\" She is portrayed as a talented and beautiful woman who captures the attention of Sherlock Holmes, who refers to her as \"the woman.\" Adler is known for her intelligence and resourcefulness, and she plays a significant role in the story as she outsmarts Holmes, which is a rare occurrence for the famous detective.\n"
     ]
    }
   ],
   "source": [
    "print(\"# User Query:\\n\", response[\"query\"])\n",
    "print(\"\\n# LLM Response:\\n\", response[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce425f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragas_eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
