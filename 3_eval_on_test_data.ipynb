{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b411fe2",
   "metadata": {},
   "source": [
    "- Run evaluation metrics on generated test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5aef6564",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import (\n",
    "    compute_context_precision_score,\n",
    "    compute_context_recall_score,\n",
    "    compute_response_relevance_score,\n",
    "    compute_faithfulness_score,\n",
    "    compute_factual_correctness_score,\n",
    ")\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import ChatOpenAI\n",
    "from ragas.llms.base import llm_factory\n",
    "from IPython.display import Markdown, display\n",
    "import ast\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ada71cbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(\"configs.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3d902f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize LLMs and embedding models\n",
    "llm_as_judge = llm_factory(\"gpt-4o-mini\")\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edd26411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "TEST_DATA_PATH = \"generated_test_data/test_data.csv\"\n",
    "RESPONSE_DATA_DIR = \"generated_responses\"\n",
    "os.makedirs(RESPONSE_DATA_DIR, exist_ok=True)\n",
    "RESPONSE_DATA_PATH = os.path.join(RESPONSE_DATA_DIR, \"rag_responses_v1.csv\")\n",
    "VECTOR_DB_DIR = \"vector_db\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21880637",
   "metadata": {},
   "source": [
    "Read generated test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04ff8c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the generated test data\n",
    "test_data_df = pd.read_csv(TEST_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "939fd57a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63c7f246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What impression did Jonathan Harker have of Bu...</td>\n",
       "      <td>['JONATHAN HARKER’S JOURNAL (_Kept in shorthan...</td>\n",
       "      <td>Jonathan Harker described Buda-Pesth as a wond...</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the Golden Krone Hotel like?</td>\n",
       "      <td>['saw little towns or castles on the top of st...</td>\n",
       "      <td>The Golden Krone Hotel is described as thoroug...</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What significance does St. George’s Day hold i...</td>\n",
       "      <td>['4 May._--I found that my landlord had got a ...</td>\n",
       "      <td>St. George’s Day is significant as it is descr...</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In the context of the narrative, what signific...</td>\n",
       "      <td>['5 May. The Castle._--The grey of the morning...</td>\n",
       "      <td>'Ordog' translates to 'Satan' in the local lan...</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Why the Hospadars no fix things for fear of th...</td>\n",
       "      <td>['the Hospadars would not repair them, lest th...</td>\n",
       "      <td>The Hospadars would not repair them, lest the ...</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0  What impression did Jonathan Harker have of Bu...   \n",
       "1               What is the Golden Krone Hotel like?   \n",
       "2  What significance does St. George’s Day hold i...   \n",
       "3  In the context of the narrative, what signific...   \n",
       "4  Why the Hospadars no fix things for fear of th...   \n",
       "\n",
       "                                  reference_contexts  \\\n",
       "0  ['JONATHAN HARKER’S JOURNAL (_Kept in shorthan...   \n",
       "1  ['saw little towns or castles on the top of st...   \n",
       "2  ['4 May._--I found that my landlord had got a ...   \n",
       "3  ['5 May. The Castle._--The grey of the morning...   \n",
       "4  ['the Hospadars would not repair them, lest th...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  Jonathan Harker described Buda-Pesth as a wond...   \n",
       "1  The Golden Krone Hotel is described as thoroug...   \n",
       "2  St. George’s Day is significant as it is descr...   \n",
       "3  'Ordog' translates to 'Satan' in the local lan...   \n",
       "4  The Hospadars would not repair them, lest the ...   \n",
       "\n",
       "                        synthesizer_name  \n",
       "0  single_hop_specific_query_synthesizer  \n",
       "1  single_hop_specific_query_synthesizer  \n",
       "2  single_hop_specific_query_synthesizer  \n",
       "3  single_hop_specific_query_synthesizer  \n",
       "4  single_hop_specific_query_synthesizer  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b35af81",
   "metadata": {},
   "source": [
    "initialize retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fd16a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load persistent vector DB ===\n",
    "vectordb = Chroma(\n",
    "    persist_directory=VECTOR_DB_DIR,\n",
    "    embedding_function=OpenAIEmbeddings(model=\"text-embedding-3-small\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03aae2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77ef5cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the RetrievalQA chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    return_source_documents=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78de8689",
   "metadata": {},
   "source": [
    "generate responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd8c5d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_obj_arr = []\n",
    "for _, row in test_data_df.iterrows():\n",
    "    response = qa_chain.invoke(row[\"user_input\"])\n",
    "    response_obj_arr.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5befefd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save responses to new dataframe using response_obj_arr\n",
    "response_df = pd.DataFrame(\n",
    "    {\n",
    "        \"query\": [resp[\"query\"] for resp in response_obj_arr],\n",
    "        \"result\": [resp[\"result\"] for resp in response_obj_arr],\n",
    "        \"source_documents_names_arr\": [\n",
    "            [doc.metadata[\"source\"] for doc in resp[\"source_documents\"]]\n",
    "            for resp in response_obj_arr\n",
    "        ],\n",
    "        \"source_documents_contents_arr\": [\n",
    "            [doc.page_content for doc in resp[\"source_documents\"]]\n",
    "            for resp in response_obj_arr\n",
    "        ],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3b68966",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_df.to_csv(RESPONSE_DATA_PATH, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d74cd25",
   "metadata": {},
   "source": [
    "evaluate responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e80f0c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_df = pd.read_csv(RESPONSE_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b599daea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>result</th>\n",
       "      <th>source_documents_names_arr</th>\n",
       "      <th>source_documents_contents_arr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What impression did Jonathan Harker have of Bu...</td>\n",
       "      <td>Jonathan Harker had a positive impression of B...</td>\n",
       "      <td>['data_files/Dracula.txt', 'data_files/Dracula...</td>\n",
       "      <td>['It was on the dark side of twilight when we ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the Golden Krone Hotel like?</td>\n",
       "      <td>The Golden Krone Hotel is described as thoroug...</td>\n",
       "      <td>['data_files/Dracula.txt', 'data_files/Dracula...</td>\n",
       "      <td>['It was on the dark side of twilight when we ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What significance does St. George’s Day hold i...</td>\n",
       "      <td>In the context of the narrative, St. George's ...</td>\n",
       "      <td>['data_files/Dracula.txt', 'data_files/Dracula...</td>\n",
       "      <td>['“It is the eve of St. George’s Day. Do you n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In the context of the narrative, what signific...</td>\n",
       "      <td>In the context of the narrative, the term 'Ord...</td>\n",
       "      <td>['data_files/Dracula.txt', 'data_files/Dracula...</td>\n",
       "      <td>['When I got on the coach the driver had not t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Why the Hospadars no fix things for fear of th...</td>\n",
       "      <td>The Hospadars did not repair the roads for fea...</td>\n",
       "      <td>['data_files/Dracula.txt', 'data_files/Dracula...</td>\n",
       "      <td>['road is in summertime excellent, but that it...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  What impression did Jonathan Harker have of Bu...   \n",
       "1               What is the Golden Krone Hotel like?   \n",
       "2  What significance does St. George’s Day hold i...   \n",
       "3  In the context of the narrative, what signific...   \n",
       "4  Why the Hospadars no fix things for fear of th...   \n",
       "\n",
       "                                              result  \\\n",
       "0  Jonathan Harker had a positive impression of B...   \n",
       "1  The Golden Krone Hotel is described as thoroug...   \n",
       "2  In the context of the narrative, St. George's ...   \n",
       "3  In the context of the narrative, the term 'Ord...   \n",
       "4  The Hospadars did not repair the roads for fea...   \n",
       "\n",
       "                          source_documents_names_arr  \\\n",
       "0  ['data_files/Dracula.txt', 'data_files/Dracula...   \n",
       "1  ['data_files/Dracula.txt', 'data_files/Dracula...   \n",
       "2  ['data_files/Dracula.txt', 'data_files/Dracula...   \n",
       "3  ['data_files/Dracula.txt', 'data_files/Dracula...   \n",
       "4  ['data_files/Dracula.txt', 'data_files/Dracula...   \n",
       "\n",
       "                       source_documents_contents_arr  \n",
       "0  ['It was on the dark side of twilight when we ...  \n",
       "1  ['It was on the dark side of twilight when we ...  \n",
       "2  ['“It is the eve of St. George’s Day. Do you n...  \n",
       "3  ['When I got on the coach the driver had not t...  \n",
       "4  ['road is in summertime excellent, but that it...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b012b304",
   "metadata": {},
   "source": [
    "# Context Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "565aea66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute context precision scores\n",
    "precision_score_arr = []\n",
    "for i, row in response_df.iterrows():\n",
    "\n",
    "    # get the relevant contexts for generated response\n",
    "    retrieved_context_arr = ast.literal_eval(row[\"source_documents_contents_arr\"])\n",
    "\n",
    "    # compute context precision score\n",
    "    precision_score = await compute_context_precision_score(\n",
    "        llm_as_judge,\n",
    "        row[\"query\"],\n",
    "        retrieved_context_arr,\n",
    "        row[\"result\"],\n",
    "    )\n",
    "    precision_score_arr.append(precision_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2076692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3333333333,\n",
       " 0.9999999999,\n",
       " 0.9999999999,\n",
       " 0.8333333332916666,\n",
       " 0.999999999975,\n",
       " 0.99999999995,\n",
       " 0.999999999975,\n",
       " 0.9999999999,\n",
       " 0.999999999975,\n",
       " 0.999999999975]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0758f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Context Precision: 0.9166666666141667\n"
     ]
    }
   ],
   "source": [
    "# what is average precision?\n",
    "average_precision = (\n",
    "    sum(precision_score_arr) / len(precision_score_arr) if precision_score_arr else 0\n",
    ")\n",
    "print(f\"Average Context Precision: {average_precision}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a34b13c",
   "metadata": {},
   "source": [
    "# Context Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84780ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute context recall scores\n",
    "recall_score_arr = []\n",
    "for i, row in response_df.iterrows():\n",
    "\n",
    "    # get the relevant contexts for generated response\n",
    "    retrieved_context_arr = ast.literal_eval(row[\"source_documents_contents_arr\"])\n",
    "\n",
    "    # compute context recall score\n",
    "    recall_score = await compute_context_recall_score(\n",
    "        llm_as_judge,\n",
    "        row[\"query\"],\n",
    "        test_data_df.loc[i, \"reference\"],\n",
    "        retrieved_context_arr,\n",
    "    )\n",
    "    recall_score_arr.append(recall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "159e0860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 0.75, 1.0, 1.0, 1.0, 1.0, 0.5, 0.75, 1.0, 0.0]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca5fa146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Context Recall: 0.8\n"
     ]
    }
   ],
   "source": [
    "# what is average recall?\n",
    "average_recall = (\n",
    "    sum(recall_score_arr) / len(recall_score_arr) if recall_score_arr else 0\n",
    ")\n",
    "print(f\"Average Context Recall: {average_recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f919851d",
   "metadata": {},
   "source": [
    "# Response Relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "810b881f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute response relevance scores\n",
    "relevance_score_arr = []\n",
    "for i, row in response_df.iterrows():\n",
    "\n",
    "    # compute response relevance score\n",
    "    relevance_score = await compute_response_relevance_score(\n",
    "        llm_as_judge,\n",
    "        embedding_model,\n",
    "        row[\"query\"],\n",
    "        row[\"result\"],\n",
    "    )\n",
    "    relevance_score_arr.append(relevance_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76c6df4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.9617870340333668),\n",
       " np.float64(0.8488536721165306),\n",
       " np.float64(0.9474903782993339),\n",
       " np.float64(0.9083116486533589),\n",
       " np.float64(0.6881438184553886),\n",
       " np.float64(0.9655675728668855),\n",
       " np.float64(0.8556736335230722),\n",
       " np.float64(0.9559870690058007),\n",
       " np.float64(0.9175456113544486),\n",
       " np.float64(0.9440661760843473)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevance_score_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cefdf7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Response Relevance: 0.8993426614392532\n"
     ]
    }
   ],
   "source": [
    "# what is average relevance?\n",
    "average_relevance = (\n",
    "    sum(relevance_score_arr) / len(relevance_score_arr) if relevance_score_arr else 0\n",
    ")\n",
    "print(f\"Average Response Relevance: {average_relevance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620f2e82",
   "metadata": {},
   "source": [
    "# Faithfulness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "962abb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute faithfulness scores\n",
    "faithfulness_score_arr = []\n",
    "for i, row in response_df.iterrows():\n",
    "\n",
    "    # get the relevant contexts for generated response\n",
    "    retrieved_context_arr = ast.literal_eval(row[\"source_documents_contents_arr\"])\n",
    "\n",
    "    # compute faithfulness score\n",
    "    faithfulness_score = await compute_faithfulness_score(\n",
    "        llm_as_judge,\n",
    "        row[\"query\"],\n",
    "        retrieved_context_arr,\n",
    "        row[\"result\"],\n",
    "    )\n",
    "    faithfulness_score_arr.append(faithfulness_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1fd750a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, 1.0, 0.375, 0.8, 1.0, 0.45, 1.0, 1.0, 1.0]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faithfulness_score_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c308ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Response Faithfulness: 0.8625\n"
     ]
    }
   ],
   "source": [
    "# what is average faithfulness?\n",
    "average_faithfulness = (\n",
    "    sum(faithfulness_score_arr) / len(faithfulness_score_arr)\n",
    "    if faithfulness_score_arr\n",
    "    else 0\n",
    ")\n",
    "print(f\"Average Response Faithfulness: {average_faithfulness}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da59e9b",
   "metadata": {},
   "source": [
    "# Factual Correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d0a93968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>result</th>\n",
       "      <th>source_documents_names_arr</th>\n",
       "      <th>source_documents_contents_arr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What impression did Jonathan Harker have of Bu...</td>\n",
       "      <td>Jonathan Harker had a positive impression of B...</td>\n",
       "      <td>['data_files/Dracula.txt', 'data_files/Dracula...</td>\n",
       "      <td>['It was on the dark side of twilight when we ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the Golden Krone Hotel like?</td>\n",
       "      <td>The Golden Krone Hotel is described as thoroug...</td>\n",
       "      <td>['data_files/Dracula.txt', 'data_files/Dracula...</td>\n",
       "      <td>['It was on the dark side of twilight when we ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What significance does St. George’s Day hold i...</td>\n",
       "      <td>In the context of the narrative, St. George's ...</td>\n",
       "      <td>['data_files/Dracula.txt', 'data_files/Dracula...</td>\n",
       "      <td>['“It is the eve of St. George’s Day. Do you n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In the context of the narrative, what signific...</td>\n",
       "      <td>In the context of the narrative, the term 'Ord...</td>\n",
       "      <td>['data_files/Dracula.txt', 'data_files/Dracula...</td>\n",
       "      <td>['When I got on the coach the driver had not t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Why the Hospadars no fix things for fear of th...</td>\n",
       "      <td>The Hospadars did not repair the roads for fea...</td>\n",
       "      <td>['data_files/Dracula.txt', 'data_files/Dracula...</td>\n",
       "      <td>['road is in summertime excellent, but that it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What role does the King play in the quest for ...</td>\n",
       "      <td>The King plays a central role in the quest for...</td>\n",
       "      <td>['data_files/The Adventures of Sherlock Holmes...</td>\n",
       "      <td>['“On the contrary, my dear sir,” cried the Ki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What connection does the character's journey f...</td>\n",
       "      <td>The character's journey from London to Bistrit...</td>\n",
       "      <td>['data_files/Dracula.txt', 'data_files/Dracula...</td>\n",
       "      <td>['It was on the dark side of twilight when we ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What was Watson's role in the unexpected marri...</td>\n",
       "      <td>Watson's role in the unexpected marriage cerem...</td>\n",
       "      <td>['data_files/The Adventures of Sherlock Holmes...</td>\n",
       "      <td>['“‘Thank God,’ he cried. ‘You’ll do. Come! Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What experiences did Jonathan Harker have in B...</td>\n",
       "      <td>In Bistritz, Jonathan Harker's experiences ref...</td>\n",
       "      <td>['data_files/Dracula.txt', 'data_files/Dracula...</td>\n",
       "      <td>['It was on the dark side of twilight when we ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Whaat are the connections between the characte...</td>\n",
       "      <td>The character's journey in London is closely i...</td>\n",
       "      <td>['data_files/Dracula.txt', 'data_files/Dracula...</td>\n",
       "      <td>['the devil-begotten Hun, the Slav, the Saxon,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  What impression did Jonathan Harker have of Bu...   \n",
       "1               What is the Golden Krone Hotel like?   \n",
       "2  What significance does St. George’s Day hold i...   \n",
       "3  In the context of the narrative, what signific...   \n",
       "4  Why the Hospadars no fix things for fear of th...   \n",
       "5  What role does the King play in the quest for ...   \n",
       "6  What connection does the character's journey f...   \n",
       "7  What was Watson's role in the unexpected marri...   \n",
       "8  What experiences did Jonathan Harker have in B...   \n",
       "9  Whaat are the connections between the characte...   \n",
       "\n",
       "                                              result  \\\n",
       "0  Jonathan Harker had a positive impression of B...   \n",
       "1  The Golden Krone Hotel is described as thoroug...   \n",
       "2  In the context of the narrative, St. George's ...   \n",
       "3  In the context of the narrative, the term 'Ord...   \n",
       "4  The Hospadars did not repair the roads for fea...   \n",
       "5  The King plays a central role in the quest for...   \n",
       "6  The character's journey from London to Bistrit...   \n",
       "7  Watson's role in the unexpected marriage cerem...   \n",
       "8  In Bistritz, Jonathan Harker's experiences ref...   \n",
       "9  The character's journey in London is closely i...   \n",
       "\n",
       "                          source_documents_names_arr  \\\n",
       "0  ['data_files/Dracula.txt', 'data_files/Dracula...   \n",
       "1  ['data_files/Dracula.txt', 'data_files/Dracula...   \n",
       "2  ['data_files/Dracula.txt', 'data_files/Dracula...   \n",
       "3  ['data_files/Dracula.txt', 'data_files/Dracula...   \n",
       "4  ['data_files/Dracula.txt', 'data_files/Dracula...   \n",
       "5  ['data_files/The Adventures of Sherlock Holmes...   \n",
       "6  ['data_files/Dracula.txt', 'data_files/Dracula...   \n",
       "7  ['data_files/The Adventures of Sherlock Holmes...   \n",
       "8  ['data_files/Dracula.txt', 'data_files/Dracula...   \n",
       "9  ['data_files/Dracula.txt', 'data_files/Dracula...   \n",
       "\n",
       "                       source_documents_contents_arr  \n",
       "0  ['It was on the dark side of twilight when we ...  \n",
       "1  ['It was on the dark side of twilight when we ...  \n",
       "2  ['“It is the eve of St. George’s Day. Do you n...  \n",
       "3  ['When I got on the coach the driver had not t...  \n",
       "4  ['road is in summertime excellent, but that it...  \n",
       "5  ['“On the contrary, my dear sir,” cried the Ki...  \n",
       "6  ['It was on the dark side of twilight when we ...  \n",
       "7  ['“‘Thank God,’ he cried. ‘You’ll do. Come! Co...  \n",
       "8  ['It was on the dark side of twilight when we ...  \n",
       "9  ['the devil-begotten Hun, the Slav, the Saxon,...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5e010aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute factual correctness scores\n",
    "factual_correctness_score_arr = []\n",
    "for i, row in response_df.iterrows():\n",
    "\n",
    "    # compute factual correctness score\n",
    "    factual_correctness_score = await compute_factual_correctness_score(\n",
    "        llm_as_judge,\n",
    "        row[\"result\"],\n",
    "        test_data_df.loc[i, \"reference\"],\n",
    "    )\n",
    "    factual_correctness_score_arr.append(factual_correctness_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "02d5b757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.92),\n",
       " np.float64(0.43),\n",
       " np.float64(1.0),\n",
       " np.float64(0.73),\n",
       " np.float64(0.73),\n",
       " np.float64(0.18),\n",
       " np.float64(0.42),\n",
       " np.float64(0.46),\n",
       " np.float64(0.36),\n",
       " np.float64(0.16)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factual_correctness_score_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "25fd4e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Response Factual Correctness: 0.539\n"
     ]
    }
   ],
   "source": [
    "# what is average factual correctness score?\n",
    "average_factual_correctness = (\n",
    "    sum(factual_correctness_score_arr) / len(factual_correctness_score_arr)\n",
    "    if factual_correctness_score_arr\n",
    "    else 0\n",
    ")\n",
    "print(f\"Average Response Factual Correctness: {average_factual_correctness}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9e22f6",
   "metadata": {},
   "source": [
    "# Summary of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b3eb2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create markdown table with variables\n",
    "markdown_text = f\"\"\"\n",
    "|Evaluation Metric| Average Score|\n",
    "|----|----|\n",
    "|Context Precision|{average_precision:.3f}|\n",
    "|Context Recall|{average_recall:.3f}|\n",
    "|Response relevance|{average_relevance:.3f}|\n",
    "|Faithfulness|{average_faithfulness:.3f}|\n",
    "|Factual Correctness|{average_factual_correctness:.3f}|\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "54b68703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "|Evaluation Metric| Average Score|\n",
       "|----|----|\n",
       "|Context Precision|0.917|\n",
       "|Context Recall|0.800|\n",
       "|Response relevance|0.899|\n",
       "|Faithfulness|0.863|\n",
       "|Factual Correctness|0.539|\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(markdown_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f19f5d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragas_eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
